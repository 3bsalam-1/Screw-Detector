# Data Directory

This directory contains all dataset-related files for the Screw Detector project.

## Directory Structure

```
data/
├── configs/              # Data configuration files
│   ├── data.yaml          # Main dataset configuration
│   └── sliced_data.yaml   # Sliced dataset configuration
├── raw/                 # Original dataset
│   ├── train/            # Training images and labels
│   ├── valid/            # Validation images and labels
│   └── test/             # Test images and labels
└── processed/            # Processed datasets
    └── sliced/           # Sliced dataset tiles
```

## Dataset Information

### Classes
- Bolt
- Bottle
- Washer

### Dataset Source
- **Raw Data**: [Screw/Washer Dataset](https://www.kaggle.com/datasets/wjybuqi/screwwasher-dataset-for-small-object-detection) on Kaggle
- **Annotated Dataset**: [Bolts and Washers Dataset](https://www.kaggle.com/datasets/ahmedmohamedab/bolts-and-washers) on Kaggle

### Annotation Format
The dataset uses YOLO format with normalized coordinates:
```
<class_id> <x_center> <y_center> <width> <height>
```

Where:
- `class_id`: Integer class identifier (0=Bolt, 1=Bottle, 2=Washer)
- `x_center`, `y_center`: Normalized center coordinates (0-1)
- `width`, `height`: Normalized width and height (0-1)

## Configuration Files

### data.yaml
Main dataset configuration file for training and evaluation.

```yaml
names:
  - Bolt
  - Bottle
  - Washer
nc: 3
test: data/raw/test/images
train: data/raw/train/images
val: data/raw/valid/images
```

### sliced_data.yaml
Configuration file for the sliced dataset.

```yaml
names:
  - Bolt
  - Bottle
  - Washer
nc: 3
path: data/processed/sliced
test: test/images
train: train/images
val: val/images
```

## Dataset Statistics

Based on the original dataset:
- **Total Images**: ~250 images
- **Total Annotations**: ~8,000 objects
- **Average Object Size**: ~20px
- **Small Objects (<15px)**: ~36 objects
- **Medium Objects (15-30px)**: ~100 objects
- **Large Objects (>30px)**: ~246 objects

## Sliced Dataset

The sliced dataset is generated by dividing original images into 640x640 tiles with 128px overlap. This approach:
- Improves detection of small objects
- Provides more training samples
- Maintains object visibility threshold of 30%

### Slicing Parameters
- **Tile Size**: 640x640 pixels
- **Overlap**: 128 pixels
- **Visibility Threshold**: 0.3 (30%)
- **Output Directory**: `data/processed/sliced/`

## Usage

### Training with Original Dataset
```bash
screw-train --model yolov8s.pt --data data/configs/data.yaml --epochs 150
```

### Training with Sliced Dataset
```bash
# First, generate sliced dataset
screw-slice-dataset --data data/configs/data.yaml

# Then train on sliced data
screw-train --model yolov8s.pt --data data/configs/sliced_data.yaml --sliced-data --epochs 150
```

### Evaluation
```bash
screw-evaluate --model models/best.pt --data data/configs/data.yaml --split test
```

## Notes

- The `raw/` directory contains the original dataset with train/valid/test splits
- The `processed/sliced/` directory contains the sliced dataset tiles
- Configuration files use relative paths for portability
- Labels are stored in `labels/` subdirectories alongside images
